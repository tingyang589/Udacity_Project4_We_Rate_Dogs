{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We Rate Dogs - Data Wrangling Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this report, I outline the steps I did for this project which requires me to gather, access and then clean the datasets. The cleaned dataset when will be used for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Gather data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, I gathered 3 dataset which are provided:\n",
    "\n",
    "- <b>The WeRateDogs Twitter archive</b>. This file is given by Udacity, I download this file manually from the link provided.\n",
    "\n",
    "- <b>The tweet image predictions</b>. This file is downloaded programmatically using the Requests library from Udacity server.\n",
    "\n",
    "- <b>The tweet's JSON data</b>. This dataset is downloaded by querying the Twitter API using Tweepy library.\n",
    "\n",
    "I then read in these datasets into 3 separate dataframes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Access and Clean data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, I will describe the Access and Clean process together. I will state the quality and tidiness issues that were identified, followed by the actions that I made to fix them. \n",
    "\n",
    "There are missing data for the <code>expanded_urls</code>, these tweets were dropped from the dataset.\n",
    "\n",
    "The <code>timestamp</code> is in string format, and was converted to a time format.\n",
    "\n",
    "The terms that used to describe dogs (doggo, floofer, pupper, puppo) are in 4 different columns, they are melted into single column <code>dog_type</code>.\n",
    "\n",
    "The <code>name</code> for the dogs have some invlid names like 'none', 'a','the', it appears to me that any names begin with lower case are not a proper dog name. So I decided to recode all names that begins with a lower case to <b>None</b>.\n",
    "\n",
    "The columns like <code>retweeted_status_id, retweeted_status_user_id, retweeted_status </code> are irrelevant to our project objectives as we are only interested in the original tweets; they are dropped from the archive dataset.\n",
    "\n",
    "Some data entries have invalide number for <code>rating_denominator</code> and <code>rating_numerator</code>;  a descriptive statistics were performed and ratings with numerous large values were dropped from dataset.\n",
    "\n",
    "In the prediction table, there are tweets that do not have a predicted breed, they are then dropped from the dataset.\n",
    "\n",
    "The prediction data and API data should be merged with archive data; this is the last cleaning I did for the data. I merged the cleaned archive data with API data first, then merged again with image prediction data.\n",
    "\n",
    "Finally I saved the cleaned and merged master data on to 'twitter_master_data.csv'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
